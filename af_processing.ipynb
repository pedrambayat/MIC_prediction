{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ff8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9835.result.csv\n",
      "Skipped AF_DATA/Train/9835.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/21712.result.csv\n",
      "Skipped AF_DATA/Train/21712.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9838.result.csv\n",
      "Skipped AF_DATA/Train/9838.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7791.result.csv\n",
      "Skipped AF_DATA/Train/7791.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18865.result.csv\n",
      "Skipped AF_DATA/Train/18865.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7794.result.csv\n",
      "Skipped AF_DATA/Train/7794.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18871.result.csv\n",
      "Skipped AF_DATA/Train/18871.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7785.result.csv\n",
      "Skipped AF_DATA/Train/7785.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/20466.result.csv\n",
      "Skipped AF_DATA/Train/20466.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18867.result.csv\n",
      "Skipped AF_DATA/Train/18867.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7131.result.csv\n",
      "Skipped AF_DATA/Train/7131.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9826.result.csv\n",
      "Skipped AF_DATA/Train/9826.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9823.result.csv\n",
      "Skipped AF_DATA/Train/9823.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7775.result.csv\n",
      "Skipped AF_DATA/Train/7775.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7134.result.csv\n",
      "Skipped AF_DATA/Train/7134.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18855.result.csv\n",
      "Skipped AF_DATA/Train/18855.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9841.result.csv\n",
      "Skipped AF_DATA/Train/9841.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/6741.result.csv\n",
      "Skipped AF_DATA/Train/6741.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7796.result.csv\n",
      "Skipped AF_DATA/Train/7796.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/19146.result.csv\n",
      "Skipped AF_DATA/Train/19146.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18858.result.csv\n",
      "Skipped AF_DATA/Train/18858.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/6796.result.csv\n",
      "Skipped AF_DATA/Train/6796.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7776.result.csv\n",
      "Skipped AF_DATA/Train/7776.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18861.result.csv\n",
      "Skipped AF_DATA/Train/18861.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18870.result.csv\n",
      "Skipped AF_DATA/Train/18870.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9834.result.csv\n",
      "Skipped AF_DATA/Train/9834.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/18869.result.csv\n",
      "Skipped AF_DATA/Train/18869.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7781.result.csv\n",
      "Skipped AF_DATA/Train/7781.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7790.result.csv\n",
      "Skipped AF_DATA/Train/7790.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9839.result.csv\n",
      "Skipped AF_DATA/Train/9839.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7132.result.csv\n",
      "Skipped AF_DATA/Train/7132.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9825.result.csv\n",
      "Skipped AF_DATA/Train/9825.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7135.result.csv\n",
      "Skipped AF_DATA/Train/7135.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9840.result.csv\n",
      "Skipped AF_DATA/Train/9840.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7797.result.csv\n",
      "Skipped AF_DATA/Train/7797.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/20907.result.csv\n",
      "Skipped AF_DATA/Train/20907.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/6733.result.csv\n",
      "Skipped AF_DATA/Train/6733.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9833.result.csv\n",
      "Skipped AF_DATA/Train/9833.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/7783.result.csv\n",
      "Skipped AF_DATA/Train/7783.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/5507.result.csv\n",
      "Skipped AF_DATA/Train/5507.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9836.result.csv\n",
      "Skipped AF_DATA/Train/9836.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/9827.result.csv\n",
      "Skipped AF_DATA/Train/9827.result.csv\n",
      "Warning: No valid phi/psi angles in AF_DATA/Train/11035.result.csv\n",
      "Skipped AF_DATA/Train/11035.result.csv\n",
      "Processed 713 training files\n",
      "\n",
      "Processing test data...\n",
      "Processed 57 test files\n",
      "\n",
      "Saved training features to train_structural_features.csv\n",
      "Saved test features to test_structural_features.csv\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION: Define paths here\n",
    "# ============================================================================\n",
    "TRAIN_DIR = \"AF_DATA/Train\"\n",
    "TEST_DIR = \"AF_DATA/Test\"\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "def circular_variance(angles):\n",
    "    \"\"\"\n",
    "    Calculate circular variance for angles (1 - R).\n",
    "    R is the mean resultant length after converting angles to unit vectors.\n",
    "    \"\"\"\n",
    "    if len(angles) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert angles to radians\n",
    "    angles_rad = np.deg2rad(angles)\n",
    "    \n",
    "    # Convert to unit vectors\n",
    "    x = np.cos(angles_rad)\n",
    "    y = np.sin(angles_rad)\n",
    "    \n",
    "    # Calculate mean resultant length R\n",
    "    R = np.sqrt(np.mean(x)**2 + np.mean(y)**2)\n",
    "    \n",
    "    # Circular variance = 1 - R\n",
    "    return 1 - R\n",
    "\n",
    "def parse_contact_map(contact_map_str):\n",
    "    \"\"\"\n",
    "    Parse contact map string representation safely.\n",
    "    Handles both integer and string keys.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to parse as dictionary\n",
    "        contact_dict = ast.literal_eval(contact_map_str)\n",
    "        \n",
    "        # Convert keys to integers if they're strings\n",
    "        if isinstance(contact_dict, dict):\n",
    "            parsed_dict = {}\n",
    "            for key, value in contact_dict.items():\n",
    "                try:\n",
    "                    int_key = int(key)\n",
    "                    parsed_dict[int_key] = value\n",
    "                except (ValueError, TypeError):\n",
    "                    parsed_dict[key] = value\n",
    "            return parsed_dict\n",
    "        return contact_dict\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        return None\n",
    "\n",
    "def extract_contact_features(contact_map_str, num_residues):\n",
    "    \"\"\"\n",
    "    Extract contact map features:\n",
    "    - Avg_Degree: Mean number of contacts per residue\n",
    "    - Avg_Seq_Sep: Average sequence separation for all unique contacts\n",
    "    - Frac_Long_Range: Fraction of contacts with sequence separation >= 5\n",
    "    \"\"\"\n",
    "    contact_dict = parse_contact_map(contact_map_str)\n",
    "    \n",
    "    if contact_dict is None:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    \n",
    "    # Collect all unique contacts (i, j) where i < j\n",
    "    contacts = set()\n",
    "    degrees = np.zeros(num_residues)\n",
    "    \n",
    "    for i, contact_list in contact_dict.items():\n",
    "        try:\n",
    "            i = int(i)\n",
    "            if i >= num_residues:\n",
    "                continue\n",
    "            \n",
    "            # Count contacts for residue i\n",
    "            if isinstance(contact_list, list):\n",
    "                for j, has_contact in enumerate(contact_list):\n",
    "                    if has_contact == 1 and j < num_residues:\n",
    "                        if i < j:\n",
    "                            contacts.add((i, j))\n",
    "                        degrees[i] += 1\n",
    "        except (ValueError, TypeError, IndexError):\n",
    "            continue\n",
    "    \n",
    "    # Calculate Avg_Degree\n",
    "    avg_degree = np.mean(degrees) if len(degrees) > 0 else 0.0\n",
    "    \n",
    "    # Calculate Avg_Seq_Sep and Frac_Long_Range\n",
    "    if len(contacts) == 0:\n",
    "        return avg_degree, 0.0, 0.0\n",
    "    \n",
    "    seq_separations = [abs(j - i) for i, j in contacts]\n",
    "    avg_seq_sep = np.mean(seq_separations)\n",
    "    frac_long_range = np.mean([sep >= 5 for sep in seq_separations])\n",
    "    \n",
    "    return avg_degree, avg_seq_sep, frac_long_range\n",
    "\n",
    "def process_single_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single CSV file and extract all 8 features.\n",
    "    Returns a dictionary with features or None if processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(filepath)\n",
    "        \n",
    "        # Check if file is empty\n",
    "        if df.empty:\n",
    "            print(f\"Warning: Empty file {filepath}\")\n",
    "            return None\n",
    "        \n",
    "        # Get protein name from filename\n",
    "        protein_name = Path(filepath).stem\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 1. Confidence Features\n",
    "        # ====================================================================\n",
    "        plddt_values = df['pLDDT'].dropna()\n",
    "        if len(plddt_values) == 0:\n",
    "            print(f\"Warning: No pLDDT values in {filepath}\")\n",
    "            return None\n",
    "        \n",
    "        plddt_mean = plddt_values.mean()\n",
    "        plddt_std = plddt_values.std()\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 2. Secondary Structure Features\n",
    "        # ====================================================================\n",
    "        phi_values = df['phi'].dropna()\n",
    "        psi_values = df['psi'].dropna()\n",
    "        \n",
    "        # Get valid indices where both phi and psi are available\n",
    "        valid_indices = df.index[df['phi'].notna() & df['psi'].notna()]\n",
    "        \n",
    "        if len(valid_indices) == 0:\n",
    "            print(f\"Warning: No valid phi/psi angles in {filepath}\")\n",
    "            return None\n",
    "        \n",
    "        # Helix: phi in [-90, -30] and psi in [-80, -10]\n",
    "        helix_mask = (\n",
    "            (df.loc[valid_indices, 'phi'] >= -90) & \n",
    "            (df.loc[valid_indices, 'phi'] <= -30) &\n",
    "            (df.loc[valid_indices, 'psi'] >= -80) & \n",
    "            (df.loc[valid_indices, 'psi'] <= -10)\n",
    "        )\n",
    "        frac_helix = helix_mask.sum() / len(valid_indices)\n",
    "        \n",
    "        # Sheet: phi in [-180, -90] and psi in [90, 180]\n",
    "        sheet_mask = (\n",
    "            (df.loc[valid_indices, 'phi'] >= -180) & \n",
    "            (df.loc[valid_indices, 'phi'] <= -90) &\n",
    "            (df.loc[valid_indices, 'psi'] >= 90) & \n",
    "            (df.loc[valid_indices, 'psi'] <= 180)\n",
    "        )\n",
    "        frac_sheet = sheet_mask.sum() / len(valid_indices)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 3. Rigidity Features\n",
    "        # ====================================================================\n",
    "        phi_circ_var = circular_variance(phi_values.values)\n",
    "        psi_circ_var = circular_variance(psi_values.values)\n",
    "        \n",
    "        # Backbone_Rigidity = average of phi and psi circular variance\n",
    "        if np.isnan(phi_circ_var) or np.isnan(psi_circ_var):\n",
    "            backbone_rigidity = np.nan\n",
    "        else:\n",
    "            backbone_rigidity = (phi_circ_var + psi_circ_var) / 2.0\n",
    "        \n",
    "        # ====================================================================\n",
    "        # 4. Topology Features (Contact Map)\n",
    "        # ====================================================================\n",
    "        # Get contact map from first row (should be same for all rows)\n",
    "        contact_map_str = df['contact_map'].iloc[0]\n",
    "        num_residues = len(df)\n",
    "        \n",
    "        avg_degree, avg_seq_sep, frac_long_range = extract_contact_features(\n",
    "            contact_map_str, num_residues\n",
    "        )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Compile results\n",
    "        # ====================================================================\n",
    "        result = {\n",
    "            'protein_name': protein_name,\n",
    "            'pLDDT_mean': plddt_mean,\n",
    "            'pLDDT_std': plddt_std,\n",
    "            'Frac_Helix': frac_helix,\n",
    "            'Frac_Sheet': frac_sheet,\n",
    "            'Backbone_Rigidity': backbone_rigidity,\n",
    "            'Avg_Degree': avg_degree,\n",
    "            'Avg_Seq_Sep': avg_seq_sep,\n",
    "            'Frac_Long_Range': frac_long_range\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Process all CSV files in a directory.\n",
    "    Returns a DataFrame with all extracted features.\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(directory_path, \"*.csv\"))\n",
    "    \n",
    "    if len(csv_files) == 0:\n",
    "        print(f\"Warning: No CSV files found in {directory_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = []\n",
    "    for csv_file in csv_files:\n",
    "        result = process_single_file(csv_file)\n",
    "        if result is not None:\n",
    "            results.append(result)\n",
    "        else:\n",
    "            print(f\"Skipped {csv_file}\")\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ============================================================================\n",
    "# Main Processing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Processing training data...\")\n",
    "train_df = process_directory(TRAIN_DIR)\n",
    "print(f\"Processed {len(train_df)} training files\")\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_df = process_directory(TEST_DIR)\n",
    "print(f\"Processed {len(test_df)} test files\")\n",
    "\n",
    "# Save results\n",
    "if len(train_df) > 0:\n",
    "    train_df.to_csv(\"train_structural_features.csv\", index=False)\n",
    "    print(f\"\\nSaved training features to train_structural_features.csv\")\n",
    "else:\n",
    "    print(\"\\nWarning: No training data to save\")\n",
    "\n",
    "if len(test_df) > 0:\n",
    "    test_df.to_csv(\"test_structural_features.csv\", index=False)\n",
    "    print(f\"Saved test features to test_structural_features.csv\")\n",
    "else:\n",
    "    print(\"Warning: No test data to save\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205059a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
